{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version history:\n",
    "# 2022-12-05: v6: added function set_seed\n",
    "# 2022-12-04: v5: CatBoost and transformers are added\n",
    "# 2022-12-03: v4: added random_state=42 to make_label_distribution_equal. Fixed f-string in \"Unexpected model tag: {model_tag}\". Metrics: 0.497 +- 0.002, 0.502 +- 0.003\n",
    "# 2022-12-03: v4: added function make_label_distribution_equal, added np.std to final output\n",
    "# 2022-12-03: v3: added colab section. Metrics: 0.507, 0.497"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "McUNYSRES3BJ",
   "metadata": {
    "id": "McUNYSRES3BJ"
   },
   "source": [
    "# ===== Part0 - env preparation ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QGwHFA6bTWrP",
   "metadata": {
    "id": "QGwHFA6bTWrP"
   },
   "source": [
    "## System info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hGqZ4q0xTZzk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print system id\n",
    "!nvidia-smi\n",
    "!hostname\n",
    "!uname -a\n",
    "!df -kh /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mPQv8mUdTfBI",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V  # If version < 3.9 then some f-string features may not work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fbf57Rw8Tkbp",
   "metadata": {
    "id": "Fbf57Rw8Tkbp"
   },
   "source": [
    "## Mount drive (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iwY_m2koduAf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_USE_COLAB = None\n",
    "try:\n",
    "    PATH_MOUNT = \"/content/drive\"\n",
    "    from google.colab import drive\n",
    "    drive.mount(PATH_MOUNT)\n",
    "    TO_USE_COLAB = True\n",
    "except:\n",
    "    TO_USE_COLAB = False\n",
    "TO_USE_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sblv0ZCPeAj-",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if TO_USE_COLAB:\n",
    "    PATH_MAIN_DIR = f\"{PATH_MOUNT}/MyDrive/_PR_ROOT/_2022/2022-11_NLP-Huawei_Final_project/stocktwits_finsentiment_analysis/notebooks\"\n",
    "    #PATH_MAIN_DIR = f\"{PATH_MOUNT}/MyDrive/nlp_final_prj/\"\n",
    "else:\n",
    "    PATH_MAIN_DIR = \".\"\n",
    "assert os.path.isdir(PATH_MAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22oY2W1sT4aN",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd $PATH_MAIN_DIR  # Commented not to put there temp data\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56906c",
   "metadata": {
    "id": "eb56906c"
   },
   "source": [
    "# ===== Part 1: prepare dataset ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb4236",
   "metadata": {
    "id": "fcbb4236"
   },
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14453e",
   "metadata": {
    "id": "ea14453e"
   },
   "source": [
    "## Paths and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8566f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files and folders\n",
    "\n",
    "DIR_DATA_SRC = os.path.join(PATH_MAIN_DIR, r'../data/interim/040_output__nb010_v1')\n",
    "\n",
    "#FNAMES = ['VIX_RmSW=0_RmRep=0_1y_top10.csv', 'VIX_RmSW=0_RmRep=0_1y_top10.csv' ]  # Loads in <1 sec\n",
    "FNAMES = ['AMZN_RmSW=0_RmRep=0_1y.csv.gz', 'NFLX_RmSW=0_RmRep=0_1y.csv.gz', ]  # Loads in ~10-20 seconds\n",
    "#FNAMES = ['AAPL_RmSW=0_RmRep=0_1y.csv.gz', ]  # Loads in 20-30 sec\n",
    "\n",
    "assert os.path.isdir(DIR_DATA_SRC), f\"Folder not found: {DIR_DATA_SRC}\"\n",
    "for f in FNAMES:\n",
    "    assert os.path.isfile(os.path.join(DIR_DATA_SRC, f)), f\"File not found: {f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5806080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation settings\n",
    "\n",
    "DROP_RECORDS_BEFORE_DATE_INCLUSIVE = '2019-07-20'  # Last date in datasets is 2020-07-21\n",
    "LABEL_GEN_STRATEGY = \"d1_C=d1_O=0.5%=2cls\"  # This string is a \"key\", see function XXX for explanations\n",
    "COL_FEATURES = ['symbol', 'message', 'datetime', 'user', 'message_id', 'Date']  #, 'Time']\n",
    "COL_LABEL = 'label'\n",
    "COL_PCR = 'price_change_ratio'\n",
    "\n",
    "TEST_SIZE = 0.15\n",
    "TRAIN_SIZE = 1.0 - TEST_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca878418",
   "metadata": {
    "id": "ca878418"
   },
   "source": [
    "## Defs\n",
    "Here are \"pure\" functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d990e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More info: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "def init_seeds(seed=42):\n",
    "    # Python and CPU-related entropy  \n",
    "    random.seed(seed)      \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # torch.use_deterministic_algorithms(True)   # Raises a CUBLAS error on some cases\n",
    "    # os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Does not help for the error above\n",
    "\n",
    "    # GPU-related entropy\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # gpu vars\n",
    "        torch.backends.cudnn.benchmark = False  # See \n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81fd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the \"worker_init_fn\" param of torch DataLoader\n",
    "# More info: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    random.seed(worker_seed)\n",
    "    np.random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8863e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_details(df: pd.DataFrame):\n",
    "    print(\"\\nHead:\\n\", df.head())\n",
    "    print(\"\\nTail:\\n\", df.tail())\n",
    "    print('\\nInfo:')\n",
    "    df.info()  # This method prints by itself\n",
    "    print('\\nDescribe:\\n', df.describe(include='all'))  #, datetime_is_numeric=True)) - to suppress warnings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pandas_file(file_path: str, verbose=True):\n",
    "    # Prepare\n",
    "    assert os.path.isfile(file_path), f\"Cannot find file: '{file_path}', cur folder: '{os. getcwd()}'\"    \n",
    "    print(\"Loading data from: \", file_path)\n",
    "        \n",
    "    # Do the load\n",
    "    start_time = time.time()\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Success. Shape: {df.shape}, elapsed seconds: {time.time() - start_time:.2f}\")\n",
    "    \n",
    "    # Dump details if required\n",
    "    if verbose:\n",
    "        print_df_details(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(df_list: list, verbose=True) -> pd.DataFrame:\n",
    "    if verbose:\n",
    "        for df in df_list:\n",
    "            print(df.shape, end=';')\n",
    "    res_df = pd.concat(df_list, ignore_index=True)\n",
    "    if verbose:\n",
    "        print(\"->\", res_df.shape)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0bc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_old_dates_inplace(df: pd.DataFrame, drop_date_inclusive: str, verbose=True) -> pd.DataFrame:\n",
    "    assert isinstance(drop_date_inclusive, str)\n",
    "    old_shape = df.shape\n",
    "    df.drop(df[df['Date'] <= drop_date_inclusive].index, inplace = True)\n",
    "    print(f\"Old dates dropped. Shape before: {old_shape}, after: {df.shape}\")\n",
    "    if verbose:\n",
    "        print_df_details(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0611db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(ch):\n",
    "  if ch > 0.5:\n",
    "    return 1\n",
    "  elif ch < -0.5:\n",
    "    return -1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "def generate_labels_and_pcr_list(df: pd.DataFrame, strategy_str: str) -> list:\n",
    "    # price_change_ratio = pcr \n",
    "    if strategy_str == \"d1_C=d1_O=0.5%=2cls\":\n",
    "        assert (df['d1_O'] > 0.0).all()  # Prices must be > 0\n",
    "        assert (df['d1_C'] > 0.0).all()  # Prices must be > 0\n",
    "        rel_change_perc = (df['d1_C'] / df['d1_O'] - 1.0) * 100.0\n",
    "        # Convert from percentages to labels -1, 0, 1\n",
    "        res_series = rel_change_perc.apply(get_label)\n",
    "    else:\n",
    "        assert False, \"Unexpeced strategy_str\"\n",
    "    return res_series.to_list(), rel_change_perc.to_list()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_feature_selection(df: pd.DataFrame):\n",
    "    res_df = df[COL_FEATURES]\n",
    "    print(f\"Selected cols: {res_df.columns}\")\n",
    "    return res_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_label_transformation(df: pd.DataFrame):\n",
    "    temp_df = df.drop(df[df[COL_LABEL] == 0].index, inplace= False).copy()\n",
    "    temp_df[COL_LABEL].replace({-1:0}, inplace = True)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d63c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_real_profit_perc(y_pred, pcr_list) -> float:\n",
    "    return np.NaN  # TODO: This function is not correct, as it's necessary to aggregate predictions by date and ticker\n",
    "\n",
    "    profit_ratio = 1.0\n",
    "    assert len(y_pred) == len(pcr_list), f\"{len(y_pred)}, {len(pcr_list)}\"\n",
    "    for i, (pred, pcr) in enumerate(zip(y_pred, pcr_list)):\n",
    "        price_ratio = (pcr / 100.0 + 1.0)  # Convert from percents [-5% .. 5%] -> [-0.05 .. 0.05] -> [0.95 .. 1.05]\n",
    "        assert 0.0 < price_ratio < np.inf, f\"{i}, {price_ratio}\" \n",
    "        if pred == 1:\n",
    "            # Long\n",
    "            profit_ratio *= price_ratio\n",
    "        elif pred == 0:\n",
    "            # Short\n",
    "            profit_ratio /= price_ratio\n",
    "        else:\n",
    "            assert False, \"Unexpected label\"\n",
    "    return (profit_ratio - 1.0) * 100.0  # Profit in percents (0% - nothing changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef9cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hash_for_seq(values, hash_len=6):\n",
    "    assert isinstance(values, (list, np.ndarray, pd.Series))\n",
    "    h = hash(tuple(values))\n",
    "    return str(h)[-hash_len:]\n",
    "\n",
    "# Small unit tests\n",
    "print(calc_hash_for_seq([1, 2, 3]))\n",
    "print(calc_hash_for_seq(np.array([1, 2, 3])))\n",
    "print(calc_hash_for_seq(pd.Series([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hdZ-rWtdeMST",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label_distribution_equal(df: pd.DataFrame, random_state=42) -> pd.DataFrame:\n",
    "    \n",
    "    counts = df.label.value_counts()\n",
    "    assert len(counts == 2)  # We expect only labels 0 and 1\n",
    "\n",
    "    bigger_label = 0 if counts[0] > counts[1] else 1\n",
    "    diff = abs(counts[0] - counts[1])\n",
    "\n",
    "    res_df = df.drop(index=df[df.label == bigger_label].sample(n = diff, replace=False, random_state=random_state).index)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61a358",
   "metadata": {
    "id": "2b61a358"
   },
   "source": [
    "## Do prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535b39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#init_seeds(42)  # May be useful if torch DataLoader is used, etc.  TODO: think if required here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data, dropping old dates\n",
    "df_list = []\n",
    "for fname in FNAMES:\n",
    "    full_name = os.path.join(DIR_DATA_SRC, fname)\n",
    "    assert os.path.isfile(full_name), full_name\n",
    "    df_temp = load_pandas_file(full_name, verbose=False)\n",
    "    drop_old_dates_inplace(df_temp, DROP_RECORDS_BEFORE_DATE_INCLUSIVE, verbose=False)\n",
    "    df_list.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat loaded parts to one dataframe\n",
    "df_raw = merge_dfs(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose columns for final dataset\n",
    "df_final = do_feature_selection(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the target column\n",
    "labels, pcr_list = generate_labels_and_pcr_list(df_raw, strategy_str=LABEL_GEN_STRATEGY)\n",
    "df_final[COL_LABEL] = labels\n",
    "df_final[COL_PCR] = pcr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bac67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop labels for neutral class\n",
    "df_final = do_label_transformation(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_df_details(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c496fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[COL_LABEL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Miodtm2yXBnt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making labels distribution equal\n",
    "df_final = make_label_distribution_equal(df_final)\n",
    "df_final[COL_LABEL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d862a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cad7c0",
   "metadata": {
    "id": "93cad7c0"
   },
   "source": [
    "# ===== Part 2: Model execution and scoring ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b8bad",
   "metadata": {
    "id": "292b8bad"
   },
   "source": [
    "## Imports (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ee10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Optional\n",
    "\n",
    "# Baseline-related imports\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e135ce1",
   "metadata": {
    "id": "8e135ce1"
   },
   "source": [
    "## Defs (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df3605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_get_predictions__sklearn_classifier(model_tag: str, \n",
    "    X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.Series, seed: int) -> pd.Series:\n",
    "\n",
    "    # Initial checks\n",
    "    assert COL_PCR not in X_train.columns  # To avoid data leaks\n",
    "    \n",
    "    # Create the model with specified seed\n",
    "    if model_tag == \"dummy__most_frequent\":\n",
    "        model = DummyClassifier(strategy=\"most_frequent\", random_state=seed)\n",
    "    elif model_tag == \"dummy__uniform\":\n",
    "        model = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "    else:\n",
    "        assert False, f\"Unexpected model tag: {model_tag}\"\n",
    "    \n",
    "    # Train the model    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    return y_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9U-oABvcbRjc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "\n",
    "def train_model_and_get_predictions__NB_classifier(model_tag: str, \n",
    "    X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.Series, seed: int, out_model_file: Optional[str]=None) -> pd.Series:\n",
    "\n",
    "    # Initial checks\n",
    "    assert COL_PCR not in X_train.columns  # To avoid data leaks\n",
    "    \n",
    "    # Create the vectorizer and model with specified params\n",
    "    if model_tag == \"NaiveBayes_words_ng1-3_alhpa0.1\":\n",
    "        tf_idf = TfidfVectorizer(use_idf=True, ngram_range=(1,3), analyzer='word')\n",
    "        model = MultinomialNB(alpha=0.1)\n",
    "    elif model_tag == \"NaiveBayes_words_ng2-2_alhpa0.1\":\n",
    "        tf_idf = TfidfVectorizer(use_idf=True, ngram_range=(2,2), analyzer='word')\n",
    "        model = MultinomialNB(alpha=0.1)        \n",
    "    else:\n",
    "        assert False, f\"Unexpected model tag: {model_tag}\"\n",
    "    \n",
    "    # Prepare tf-idf features (!huge sparse matrix)\n",
    "    train_features = tf_idf.fit_transform(X_train.message)\n",
    "    test_features = tf_idf.transform(X_test.message)\n",
    "\n",
    "    # Train the model    \n",
    "    model.fit(train_features, y_train)\n",
    "\n",
    "    # Save the model if required (will be overwritten if the file exists)\n",
    "    if out_model_file is not None:\n",
    "        pickle.dump(model, open(f\"{out_model_file}_NB.pkl\", 'wb'))\n",
    "        pickle.dump(tf_idf, open(f\"{out_model_file}_TFIDF.pkl\", 'wb'))\n",
    "        print(\"Model and tf-idf saved to output files.\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(test_features)\n",
    "    \n",
    "    return y_pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd952f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install catboost --quiet\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def train_model_and_get_predictions__catboost(model_tag: str, \n",
    "    X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.Series, seed: int) -> pd.Series:\n",
    "\n",
    "    # Initial checks\n",
    "    assert COL_PCR not in X_train.columns  # To avoid data leaks\n",
    "    \n",
    "    model = CatBoostClassifier(\n",
    "                                n_estimators=300,\n",
    "                                max_depth = 8,\n",
    "                                task_type = 'GPU',\n",
    "                                verbose = 0\n",
    "                                )\n",
    "    \n",
    "    # Train the model    \n",
    "    model.fit(X_train.loc[:,['message']], y_train, text_features=['message'])\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test.loc[:,['message']])\n",
    "    \n",
    "    return y_pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16cf902",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb --quiet\n",
    "!pip install simpletransformers --quiet\n",
    "\n",
    "import torch\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "def train_model_and_get_predictions__transformer(model_tag: str, \n",
    "    X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.Series, seed: int) -> pd.Series:\n",
    "\n",
    "    # Initial checks\n",
    "    assert COL_PCR not in X_train.columns  # To avoid data leaks\n",
    "    \n",
    "    is_cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "    model_args = ClassificationArgs()\n",
    "    model_args.num_train_epochs = 2\n",
    "    model_args.regression = False\n",
    "    model_args.use_multiprocessing=is_cuda\n",
    "    model_args.use_multiprocessing_for_evaluation=is_cuda\n",
    "    model_args.overwrite_output_dir=True\n",
    "    model_args.train_batch_size = 128\n",
    "\n",
    "    model = ClassificationModel(\n",
    "                                \"roberta\",\n",
    "                                \"distilroberta-base\",\n",
    "                                num_labels=2,\n",
    "                                use_cuda=is_cuda,\n",
    "                                args=model_args\n",
    "                                )\n",
    "    \n",
    "    # Train the model    \n",
    "    tmp_df = pd.concat([X_train['message'], y_train], axis=1)\n",
    "    tmp_df.columns = [\"text\", \"labels\"]\n",
    "    model.train_model(tmp_df)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred, _ = model.predict(list(X_test['message']))\n",
    "    \n",
    "    return y_pred   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ANO_eEuDtVpI",
   "metadata": {
    "id": "ANO_eEuDtVpI"
   },
   "source": [
    "# Новый раздел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EaOSk0E5bjb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aWJVHx0qbkgR",
   "metadata": {
    "id": "aWJVHx0qbkgR"
   },
   "source": [
    "## Main function (cycle for several seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch split-train-predict-metrics cycle for several seeds\n",
    "def get_model_score_distribution(model_tag: str, df: pd.DataFrame, launch_cnt: int = 5, verbose=True):\n",
    "    result = []\n",
    "    print(\"Legend: seed; X_train shape; X_test_shape; y_train shape,hash,sum; y_test shape,hash,sum\")\n",
    "    for seed in range(42, 42 + launch_cnt):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df[COL_FEATURES + [COL_PCR]], df[COL_LABEL],\n",
    "            # stratify=df[COL_LABEL], # Note: stratification leads to the same test set (though shuffled)\n",
    "            shuffle=True,\n",
    "            random_state = seed, \n",
    "            test_size = TEST_SIZE\n",
    "        )\n",
    "        # Note: equal hash means binary equality, equal sum means the same rows but shuffled\n",
    "        print(f\"After split: {seed}, {X_train.shape}; {X_test.shape}; {y_train.shape},{calc_hash_for_seq(y_train)},{sum(y_train)};\"\n",
    "              + f\" {y_test.shape},{calc_hash_for_seq(y_test)},{sum(y_test)}\")\n",
    "\n",
    "        # Separate price_change_ratio from the data\n",
    "        pcr_train = X_train[COL_PCR]; X_train.drop(COL_PCR, axis=1, inplace=True)\n",
    "        pcr_test = X_test[COL_PCR]; X_test.drop(COL_PCR, axis=1, inplace=True)\n",
    "\n",
    "        # Launch model-specific method\n",
    "        y_pred = None\n",
    "        if model_tag.startswith('dummy_'):\n",
    "            y_pred = train_model_and_get_predictions__sklearn_classifier(model_tag, X_train, y_train, X_test, seed)\n",
    "        elif model_tag.startswith('NaiveBayes_'):\n",
    "            out_model_path = f\"naive_bayes_model__seed{seed}\"\n",
    "            y_pred = train_model_and_get_predictions__NB_classifier(model_tag, X_train, y_train, X_test, seed, out_model_path)\n",
    "        elif model_tag =='catboost':\n",
    "            y_pred = train_model_and_get_predictions__catboost(model_tag, X_train, y_train, X_test, seed)\n",
    "        elif model_tag =='transformer':\n",
    "            y_pred = train_model_and_get_predictions__transformer(model_tag, X_train, y_train, X_test, seed)\n",
    "        else:\n",
    "            assert False, f\"Unexpected model tag: {model_tag}\"\n",
    "\n",
    "        # Calc score\n",
    "        score1 = accuracy_score(y_test, y_pred)\n",
    "        #score2 = calc_real_profit_perc(y_pred, pcr_test)\n",
    "        #score3 = calc_real_profit_perc(y_train[:100], pcr_train[:100])\n",
    "        #result.append(f\"{score1:.5f}, {score2:.2f}%, {score3:.2f}%\")\n",
    "        result.append(score1)\n",
    "            \n",
    "        if verbose:\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            print(classification_report(y_test, y_pred, digits=3))\n",
    "                    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c663a",
   "metadata": {
    "id": "801c663a"
   },
   "source": [
    "## Launch the model training/estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6fce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"dummy__most_frequent\"\n",
    "results = get_model_score_distribution(model_tag, df_final, verbose=False)\n",
    "print(\"Sorted results (accuracy):\", sorted(results))\n",
    "print(f\"Mean accuracy: {np.mean(results):.3f} +- {np.std(results):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e48423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"dummy__uniform\"\n",
    "results = get_model_score_distribution(model_tag, df_final, launch_cnt = 10, verbose=False)\n",
    "print(\"Sorted results (accuracy):\", sorted(results))\n",
    "print(f\"Mean accuracy: {np.mean(results):.3f} +- {np.std(results):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hP3L2Vd7b9U1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # All models below are already saved to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cD-DRfkfb6j-",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"NaiveBayes_words_ng1-3_alhpa0.1\"  # Mean accuracy: 0.568 +- 0.002\n",
    "#model_tag = \"NaiveBayes_words_ng2-2_alhpa0.1\"  # Mean accuracy: 0.559 +- 0.002\n",
    "results = get_model_score_distribution(model_tag, df_final, launch_cnt = 2, verbose=False)\n",
    "print(\"Sorted results (accuracy):\", sorted(results))\n",
    "print(f\"Mean accuracy: {np.mean(results):.3f} +- {np.std(results):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WsQcEtiVlP0W",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /content/naive_bayes_model__seed42_*.pkl $PATH_MAIN_DIR/../models/\n",
    "! cp /content/naive_bayes_model__seed43_*.pkl $PATH_MAIN_DIR/../models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"catboost\"\n",
    "results = get_model_score_distribution(model_tag, df_final, launch_cnt = 5, verbose=False)\n",
    "print(\"Sorted results (accuracy):\", sorted(results))\n",
    "print(f\"Mean accuracy: {np.mean(results):.3f} +- {np.std(results):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf0eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"transformer\"\n",
    "results = get_model_score_distribution(model_tag, df_final, launch_cnt = 5, verbose=False)\n",
    "print(\"Sorted results (accuracy):\", sorted(results))\n",
    "print(f\"Mean accuracy: {np.mean(results):.3f} +- {np.std(results):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HP75AXvQl-CW",
   "metadata": {
    "id": "HP75AXvQl-CW"
   },
   "source": [
    "# Model blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ydZzEr9smKU_",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make test set for specific seed\n",
    "BLEND_SEED = 42\n",
    "print(\"Legend: seed; X_test_shape; hash,sum; y_test shape,hash,sum\")\n",
    "\n",
    "_, X_test, _, y_test = train_test_split(\n",
    "    df_final[COL_FEATURES + [COL_PCR]], df_final[COL_LABEL],\n",
    "    # stratify=df[COL_LABEL], # Note: stratification leads to the same test set (though shuffled)\n",
    "    shuffle=True,\n",
    "    random_state = BLEND_SEED, \n",
    "    test_size = TEST_SIZE\n",
    ")\n",
    "# Note: equal hash means binary equality, equal sum means the same rows but shuffled\n",
    "print(f\"After split: {BLEND_SEED} {X_test.shape}; \"\n",
    "      + f\" {y_test.shape},{calc_hash_for_seq(y_test)},{sum(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xn92wM-umAgN",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NB model\n",
    "! cp $PATH_MAIN_DIR/../models/naive_bayes_model__seed42_*.pkl /content/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xW9U8e5MntDT",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb = pickle.load(open('naive_bayes_model__seed42_NB.pkl', 'rb'))\n",
    "model_tfidf = pickle.load(open('naive_bayes_model__seed42_TFIDF.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "APIncNLlmDnb",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_tfidf.transform(X_test.message)\n",
    "score_nb = model_nb.score(features, y_test)\n",
    "assert np.isclose(score_nb, 0.572, atol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kaAYKLjcn3SZ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities\n",
    "probs_nb = model_nb.predict_proba(features)[:, 1]\n",
    "probs_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CnpBwHxzq1cU",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CB model\n",
    "! cp $PATH_MAIN_DIR/../models/catboost_model_0559.cbm /content/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QNG3SVZhrOpM",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "model_cb = CatBoostClassifier()\n",
    "model_cb.load_model(\"catboost_model_0559.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1FrUgEZTrdkf",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cb = model_cb.score(X_test.loc[:,['message']], y_test)\n",
    "assert np.isclose(score_cb, 0.559, atol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OFkccdrvr3hh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities\n",
    "probs_cb = model_cb.predict_proba(X_test.loc[:,['message']])[:, 1]\n",
    "probs_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GJs7c6WmskDx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transformer\n",
    "! cp $PATH_MAIN_DIR/../models/roberta_model_0548.zip /content/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leC27PbNsw3s",
   "metadata": {},
   "outputs": [],
   "source": [
    "! unzip roberta_model_0548.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FpJi5WPDtuP4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb --quiet\n",
    "!pip install simpletransformers --quiet\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skUDUD6ptDUc",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "model_args = ClassificationArgs()\n",
    "model_args.num_train_epochs = 2\n",
    "model_args.regression = False\n",
    "model_args.use_multiprocessing=is_cuda\n",
    "model_args.use_multiprocessing_for_evaluation=is_cuda\n",
    "model_args.overwrite_output_dir=True\n",
    "model_args.train_batch_size = 128\n",
    "\n",
    "model_tr = ClassificationModel(\n",
    "                            \"roberta\",\n",
    "                            \"content/roberta_model/checkpoint-2265-epoch-3/\", #\"distilroberta-base\",\n",
    "                            num_labels=2,\n",
    "                            use_cuda=is_cuda,\n",
    "                            args=model_args\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XNoyG3da0y5X",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l2BTCD6Ptljd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred_tr, y_probs_tr = model_tr.predict(list(X_test['message']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0-D3pDch0zxu",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tr = accuracy_score(y_pred_tr, y_test)\n",
    "assert np.isclose(score_tr, 0.548, atol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BfDhUA4g1P38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OlY_FPNj0noD",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_tr = softmax(y_probs_tr, axis=1)[:, 1]\n",
    "probs_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KZ-6k80euuQ-",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in np.arange(0, 1+1e-6, 0.1):\n",
    "    q = 1.0 - p\n",
    "    probs = (p * probs_nb + q * probs_cb) >= 0.5\n",
    "    y_pred = probs * 1  # Bools to ints\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{p:.2f}, {score:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r2pYit8s2IbM",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in np.arange(0, 1+1e-6, 0.1):\n",
    "    q = 1.0 - p\n",
    "    probs = (p * probs_nb + q * probs_tr) >= 0.5\n",
    "    y_pred = probs * 1  # Bools to ints\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{p:.2f}, {score:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vkLap-I6vpyN",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 0 100\n",
    "# 0 50 50\n",
    "# 0 100 0\n",
    "# 50 0 50\n",
    "# 50 50 0\n",
    "# 100 0 0\n",
    "\n",
    "max_score = 0\n",
    "max_pqz = ()\n",
    "for p in range(0, 101, 10):\n",
    "    for q in range(0, 101, 10):\n",
    "      z = 100-p-q\n",
    "      if p < 0 or q <0 or z < 0:\n",
    "          continue\n",
    "      #print(p, q, z, 100-p-q-z)\n",
    "\n",
    "      pp = p / 100.0\n",
    "      qq = q / 100.0\n",
    "      zz = z / 100.0\n",
    "      probs = (pp * probs_nb + qq * probs_cb + zz * probs_tr) >= 0.5\n",
    "      y_pred = probs * 1  # Bools to ints\n",
    "      score = accuracy_score(y_test, y_pred)\n",
    "      if max_score < score:\n",
    "          max_score = score\n",
    "          max_pqz = (pp, qq, zz)\n",
    "      print(f\"{pp:.2f}, {qq:.2f}, {zz:.2f}: {score:.4f}, {max_score:.5f}\") \n",
    "\n",
    "      # q = 1.0 - p\n",
    "      # probs = (p * probs_nb + q * probs_cb) >= 0.5\n",
    "      # y_pred = probs * 1  # Bools to ints\n",
    "      # score = accuracy_score(y_test, y_pred)\n",
    "      # print(p, score)\n",
    "\n",
    "print(f\"Best: {max_score:.5f}, {max_pqz}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7MJctiedwl71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
