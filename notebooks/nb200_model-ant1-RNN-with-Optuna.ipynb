{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version history:\n",
    "# 2022-12-13: moved sections in a logical order\n",
    "# 2022-12-03: merged changes from v4\n",
    "# 2022-12-03: created from nb102_baseline_model_v2.ipynb\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "McUNYSRES3BJ",
   "metadata": {
    "id": "McUNYSRES3BJ"
   },
   "source": [
    "# ===== Part0 - env preparation ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde3a800",
   "metadata": {
    "id": "fde3a800"
   },
   "source": [
    "## System info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print system id\n",
    "!nvidia-smi\n",
    "!hostname\n",
    "!uname -a\n",
    "!df -kh /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V  # If version < 3.9 then some f-string features may not work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654058b",
   "metadata": {
    "id": "f654058b"
   },
   "source": [
    "## Mount drive (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf93c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_USE_COLAB = None\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/drive\")\n",
    "    TO_USE_COLAB = True\n",
    "except:\n",
    "    TO_USE_COLAB = False\n",
    "TO_USE_COLAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xupoqKnA_HuV",
   "metadata": {
    "id": "xupoqKnA_HuV"
   },
   "source": [
    "## Env vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NEihSnNk-_sf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproducability, NEW: seems to not necessary\n",
    "#import os\n",
    "#os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # NEW 2022-12-05, see https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56906c",
   "metadata": {
    "id": "eb56906c"
   },
   "source": [
    "# ===== Part 1: prepare dataset ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb4236",
   "metadata": {
    "id": "fcbb4236"
   },
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075d2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14453e",
   "metadata": {
    "id": "ea14453e"
   },
   "source": [
    "## Paths and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000879da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts():\n",
    "  return datetime.datetime.now(tz=pytz.timezone(\"Europe/Minsk\")).strftime(\"%Y-%m-%dT%H%M%S\")\n",
    "START_TS = get_ts()\n",
    "START_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9edd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TO_USE_COLAB:\n",
    "    PATH_MAIN_DIR = f\"/content/drive/MyDrive/_PR_ROOT/_2022/2022-11_NLP-Huawei_Final_project/stocktwits_finsentiment_analysis/notebooks\"\n",
    "else:\n",
    "    PATH_MAIN_DIR = \".\"\n",
    "assert os.path.isdir(PATH_MAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $PATH_MAIN_DIR\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OUT_DIR = f\"../data/interim/050_output__nb200/_out_dir_{START_TS}\"\n",
    "os.mkdir(PATH_OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8566f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files and folders\n",
    "\n",
    "DIR_DATA_SRC = r'../data/interim/040_output__nb010_v1'\n",
    "#FNAMES = ['VIX_RmSW=0_RmRep=0_1y_top10.csv', 'VIX_RmSW=0_RmRep=0_1y_top10.csv' ]  # Loads in <1 sec\n",
    "FNAMES = ['AMZN_RmSW=0_RmRep=0_1y.csv.gz', 'NFLX_RmSW=0_RmRep=0_1y.csv.gz', ]  # Loads in <1 sec\n",
    "#FNAMES = ['AAPL_RmSW=0_RmRep=0_1y.csv.gz', ]  # Loads in 20-30 sec\n",
    "\n",
    "assert os.path.isdir(DIR_DATA_SRC)\n",
    "for f in FNAMES:\n",
    "    assert os.path.isfile(os.path.join(DIR_DATA_SRC, f)), f\"File not found: {f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5806080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset preparation settings\n",
    "\n",
    "DROP_RECORDS_BEFORE_DATE_INCLUSIVE = '2019-07-20'  # Last date in datasets is 2020-07-21\n",
    "LABEL_GEN_STRATEGY = \"d1_C=d1_O=0.5%=2cls\"  # This string is a \"key\", see function XXX for explanations\n",
    "COL_FEATURES = ['symbol', 'message', 'datetime', 'user', 'message_id', 'Date']  #, 'Time']\n",
    "COL_LABEL = 'label'\n",
    "COL_PCR = 'price_change_ratio'\n",
    "\n",
    "# SPLIT_SHUFFLING_SEED = 42  # If None, then no shuffling is done\n",
    "TEST_SIZE = 0.15\n",
    "TRAIN_SIZE = 1.0 - TEST_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca878418",
   "metadata": {
    "id": "ca878418"
   },
   "source": [
    "## Defs\n",
    "Here are \"pure\" functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8863e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_details(df: pd.DataFrame):\n",
    "    print(\"\\nHead:\\n\", df.head())\n",
    "    print(\"\\nTail:\\n\", df.tail())\n",
    "    print('\\nInfo:')\n",
    "    df.info()  # This method prints by itself\n",
    "    print('\\nDescribe:\\n', df.describe(include='all'))  #, datetime_is_numeric=True)) - to suppress warnings   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea0a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pandas_file(file_path: str, verbose=True):\n",
    "    # Prepare\n",
    "    assert os.path.isfile(file_path), f\"Cannot find file: '{file_path}', cur folder: '{os. getcwd()}'\"    \n",
    "    print(\"Loading data from: \", file_path)\n",
    "        \n",
    "    # Do the load\n",
    "    start_time = time.time()\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Success. Shape: {df.shape}, elapsed seconds: {time.time() - start_time:.2f}\")\n",
    "    \n",
    "    # Dump details if required\n",
    "    if verbose:\n",
    "        print_df_details(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(df_list: list, verbose=True) -> pd.DataFrame:\n",
    "    if verbose:\n",
    "        for df in df_list:\n",
    "            print(df.shape, end=';')\n",
    "    res_df = pd.concat(df_list, ignore_index=True)\n",
    "    if verbose:\n",
    "        print(\"->\", res_df.shape)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f0941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ts():\n",
    "  return datetime.datetime.now(tz=pytz.timezone(\"Europe/Minsk\")).strftime(\"%Y-%m-%dT%H%M%S\")\n",
    "# START_TS = get_ts()\n",
    "# START_TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0bc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_old_dates_inplace(df: pd.DataFrame, drop_date_inclusive: str, verbose=True) -> pd.DataFrame:\n",
    "    assert isinstance(drop_date_inclusive, str)\n",
    "    old_shape = df.shape\n",
    "    df.drop(df[df['Date'] <= drop_date_inclusive].index, inplace = True)\n",
    "    print(f\"Old dates dropped. Shape before: {old_shape}, after: {df.shape}\")\n",
    "    if verbose:\n",
    "        print_df_details(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0611db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(ch):\n",
    "  if ch > 0.5:\n",
    "    return 1\n",
    "  elif ch < -0.5:\n",
    "    return -1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "def generate_labels_and_pcr_list(df: pd.DataFrame, strategy_str: str) -> list:\n",
    "    # price_change_ratio = pcr \n",
    "    if strategy_str == \"d1_C=d1_O=0.5%=2cls\":\n",
    "        assert (df['d1_O'] > 0.0).all()  # Prices must be > 0\n",
    "        assert (df['d1_C'] > 0.0).all()  # Prices must be > 0\n",
    "        rel_change_perc = (df['d1_C'] / df['d1_O'] - 1.0) * 100.0\n",
    "        # Convert from percentages to labels -1, 0, 1\n",
    "        res_series = rel_change_perc.apply(get_label)\n",
    "    else:\n",
    "        assert False, \"Unexpeced strategy_str\"\n",
    "    return res_series.to_list(), rel_change_perc.to_list()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_feature_selection(df: pd.DataFrame):\n",
    "    res_df = df[COL_FEATURES]\n",
    "    print(f\"Selected cols: {res_df.columns}\")\n",
    "    return res_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893d9ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_label_transformation(df: pd.DataFrame):\n",
    "    temp_df = df.drop(df[df[COL_LABEL] == 0].index, inplace= False).copy()\n",
    "    temp_df[COL_LABEL].replace({-1:0}, inplace = True)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d63c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_real_profit_perc(y_pred, pcr_list) -> float:\n",
    "    return np.NaN  # TODO: This function is not correct, as it's necessary to aggregate predictions by date and ticker\n",
    "\n",
    "    profit_ratio = 1.0\n",
    "    assert len(y_pred) == len(pcr_list), f\"{len(y_pred)}, {len(pcr_list)}\"\n",
    "    for i, (pred, pcr) in enumerate(zip(y_pred, pcr_list)):\n",
    "        price_ratio = (pcr / 100.0 + 1.0)  # Convert from percents [-5% .. 5%] -> [-0.05 .. 0.05] -> [0.95 .. 1.05]\n",
    "        assert 0.0 < price_ratio < np.inf, f\"{i}, {price_ratio}\" \n",
    "        if pred == 1:\n",
    "            # Long\n",
    "            profit_ratio *= price_ratio\n",
    "        elif pred == 0:\n",
    "            # Short\n",
    "            profit_ratio /= price_ratio\n",
    "        else:\n",
    "            assert False, \"Unexpected label\"\n",
    "    return (profit_ratio - 1.0) * 100.0  # Profit in percents (0% - nothing changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef9cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_hash_for_seq(values, hash_len=6):\n",
    "    assert isinstance(values, (list, np.ndarray, pd.Series))\n",
    "    h = hash(tuple(values))\n",
    "    return str(h)[-hash_len:]\n",
    "\n",
    "# Small unit tests\n",
    "print(calc_hash_for_seq([1, 2, 3]))\n",
    "print(calc_hash_for_seq(np.array([1, 2, 3])))\n",
    "print(calc_hash_for_seq(pd.Series([1, 2, 3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TdLOTzd9v63y",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label_distribution_equal(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    counts = df.label.value_counts()\n",
    "    assert len(counts == 2)  # We expect only labels 0 and 1\n",
    "\n",
    "    bigger_label = 0 if counts[0] > counts[1] else 1\n",
    "    diff = abs(counts[0] - counts[1])\n",
    "\n",
    "    res_df = df.drop(index=df[df.label == bigger_label].sample(n = diff, replace=False, random_state=42).index)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61a358",
   "metadata": {
    "id": "2b61a358"
   },
   "source": [
    "## Do prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcf62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data, dropping old dates\n",
    "df_list = []\n",
    "for fname in FNAMES:\n",
    "    full_name = os.path.join(DIR_DATA_SRC, fname)\n",
    "    assert os.path.isfile(full_name), full_name\n",
    "    df_temp = load_pandas_file(full_name, verbose=False)\n",
    "    drop_old_dates_inplace(df_temp, DROP_RECORDS_BEFORE_DATE_INCLUSIVE, verbose=False)\n",
    "    df_list.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat loaded parts to one dataframe\n",
    "df_raw = merge_dfs(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose columns for final dataset\n",
    "df_final = do_feature_selection(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e6928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the target column\n",
    "labels, pcr_list = generate_labels_and_pcr_list(df_raw, strategy_str=LABEL_GEN_STRATEGY)\n",
    "df_final[COL_LABEL] = labels\n",
    "df_final[COL_PCR] = pcr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bac67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop labels for neutral class\n",
    "df_final = do_label_transformation(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cb7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_df_details(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c496fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[COL_LABEL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EYHENtC2wQ25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making labels distribution equal\n",
    "df_final = make_label_distribution_equal(df_final)\n",
    "df_final[COL_LABEL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d862a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cad7c0",
   "metadata": {
    "id": "93cad7c0"
   },
   "source": [
    "# ===== Part 2: Model execution and scoring ====="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b8bad",
   "metadata": {
    "id": "292b8bad"
   },
   "source": [
    "## Imports (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df081ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TO_USE_COLAB:\n",
    "    !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4ee10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import gensim.downloader\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna import create_study\n",
    "from pprint import pprint\n",
    "import random\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e135ce1",
   "metadata": {
    "id": "8e135ce1"
   },
   "source": [
    "## Defs (part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df3605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model_and_get_predictions__sklearn_classifier(model_tag: str, \n",
    "#     X_train: pd.DataFrame, y_train: pd.Series, X_test: pd.Series, seed: int) -> pd.Series:\n",
    "\n",
    "#     # Initial checks\n",
    "#     assert COL_PCR not in X_train.columns  # To avoid data leaks\n",
    "    \n",
    "#     # Create the model with specified seed\n",
    "#     if model_tag == \"dummy__most_frequent\":\n",
    "#         model = DummyClassifier(strategy=\"most_frequent\", random_state=seed)\n",
    "#     elif model_tag == \"dummy__uniform\":\n",
    "#         model = DummyClassifier(strategy=\"uniform\", random_state=seed)\n",
    "#     else:\n",
    "#         assert False, f\"Unexpected model tag: {model_tag}\"\n",
    "    \n",
    "#     # Train the model    \n",
    "#     model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Get predictions\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     return y_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sozaCblO5AH4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# References:\n",
    "# https://pytorch.org/docs/stable/notes/randomness.html\n",
    "def init_seeds(seed=123):\n",
    "    # Python and CPU-related entropy  \n",
    "    random.seed(seed)      \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # torch.use_deterministic_algorithms(True)   # Raises a CUBLAS error on some cases\n",
    "    # os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Does not help for the error above\n",
    "\n",
    "    # GPU-related entropy\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # gpu vars\n",
    "        torch.backends.cudnn.benchmark = False  # See \n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bQQg_gCx6eCa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    random.seed(worker_seed)\n",
    "    np.random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1psc8ZNGtgl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(PATH_MAIN_DIR, '../src/ant1'))\n",
    "\n",
    "from data_preprocessing import read_data, read_test, Tokenizer, TextDataset,\\\n",
    "    Vocab  #,train_test_split\n",
    "from utils import show_example\n",
    "from model import prepare_emb_matrix, RecurrentClassifier\n",
    "from trainer import Trainer\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "#assert torch.cuda.is_available()  # To be sure\n",
    "\n",
    "DATA_PORTION_TO_USE = 0.1  # May be useful for fast checks\n",
    "#DATA_PORTION_TO_USE = 0.2  # May be useful for fast checks\n",
    "#DATA_PORTION_TO_USE = 1.0  # May be useful for fast checks\n",
    "#VAL_FOLD_FRAC = 0.2  # 20% for validation data\n",
    "NUM_WORKERS = 2\n",
    "MAX_VOCAB_SIZE = 30000  # Was hardcoded\n",
    "\n",
    "#init_seeds(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7adc6f",
   "metadata": {
    "id": "4a7adc6f"
   },
   "source": [
    "## Optuna - prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c7d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill these vars for running Optuna:\n",
    "# X_train, y_train, X_test, y_test, seed\n",
    "\n",
    "seed = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_final[COL_FEATURES + [COL_PCR]], df_final[COL_LABEL],\n",
    "    # stratify=df_final[COL_LABEL], # Note: stratification leads to the same test set (though shuffled)\n",
    "    shuffle=True,\n",
    "    random_state = seed, \n",
    "    test_size = TEST_SIZE\n",
    ")\n",
    "# Note: equal hash means binary equality, equal sum means the same rows but shuffled\n",
    "print(f\"After split: {seed}, {X_train.shape}; {X_test.shape}; {y_train.shape},{calc_hash_for_seq(y_train)},{sum(y_train)};\"\n",
    "      + f\" {y_test.shape},{calc_hash_for_seq(y_test)},{sum(y_test)}\")\n",
    "\n",
    "# Separate price_change_ratio from the data\n",
    "# pcr_train = X_train[COL_PCR]; X_train.drop(COL_PCR, axis=1, inplace=True)\n",
    "# pcr_test = X_test[COL_PCR]; X_test.drop(COL_PCR, axis=1, inplace=True)\n",
    "\n",
    "X_train.drop(COL_PCR, axis=1, inplace=True)\n",
    "X_test.drop(COL_PCR, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9rYNsl-9IKVF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decimate data if required\n",
    "if DATA_PORTION_TO_USE < 1.0:\n",
    "    assert all(X_train.index == y_train.index)\n",
    "    X_train = X_train.sample(frac=DATA_PORTION_TO_USE, random_state=seed)\n",
    "    y_train = y_train.sample(frac=DATA_PORTION_TO_USE, random_state=seed)\n",
    "    assert all(X_train.index == y_train.index)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toivHUgJLF2I",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer()\n",
    "tok_texts = [tok.tokenize(t) for t in X_train.message]\n",
    "# vocab = Vocab(tok_texts, max_vocab_size=30000)\n",
    "vocab = Vocab(tok_texts, max_vocab_size=MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "m-d0AHJlOakx",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train + val folds\n",
    "#train_texts, val_texts, train_labels, val_labels = train_test_split(X_train.message.to_list(), y_train.to_list(), test_size=VAL_FOLD_FRAC)\n",
    "train_texts = X_train.message.to_list()\n",
    "val_texts = X_test.message.to_list()\n",
    "train_labels = y_train.to_list()\n",
    "val_labels = y_test.to_list()\n",
    "\n",
    "train_dataset = TextDataset([tok.tokenize(t) for t in train_texts], train_labels, vocab)\n",
    "val_dataset = TextDataset([tok.tokenize(t) for t in val_texts], val_labels, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7y0jgeUTViH2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emYMNjwcQAEM",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will download embeddings or load them from disk\n",
    "%time gensim_model = gensim.downloader.load(\"glove-wiki-gigaword-100\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cjkGBOKpP_Pk",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time emb_matrix = prepare_emb_matrix(gensim_model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del gensim_model  # To save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc0d159",
   "metadata": {
    "id": "4dc0d159"
   },
   "source": [
    "## tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43384fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seeds(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26e05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check required vars\n",
    "assert train_dataset is not None\n",
    "assert val_dataset is not None\n",
    "assert g_train_dl is not None\n",
    "\n",
    "BEST_ACC = 0.0\n",
    "\n",
    "def objective(trial):\n",
    "    global BEST_ACC\n",
    "    \n",
    "    n_hidden_layers = trial.suggest_int(\"n_hidden_layers\", 0, 3)\n",
    "    hidden_layer_size = trial.suggest_int(\"hidden_layer_size\", 10, 1000)\n",
    "    \n",
    "    config = {\n",
    "        #\"freeze\": True,  # NEW 2022-10\n",
    "        \"freeze\": trial.suggest_categorical(\"freeze\", [True, False]),\n",
    "        \"cell_type\": trial.suggest_categorical(\"cell_type\", [\"RNN\", \"LSTM\", \"GRU\"]),\n",
    "        \"cell_dropout\": trial.suggest_loguniform(\"cell_dropout\", 1e-9, 0.9),\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 10, 1000),\n",
    "        \"out_activation\": trial.suggest_categorical(\"out_activation\", \n",
    "                                                    [\"sigmoid\", \"tanh\", \"relu\", \"elu\"]),\n",
    "        \"bidirectional\": trial.suggest_categorical(\"bidirectional\", [True, False]),\n",
    "        \"out_dropout\": trial.suggest_loguniform(\"out_dropout\", 1e-9, 0.9),\n",
    "        \"out_sizes\": [hidden_layer_size] * n_hidden_layers,\n",
    "    }\n",
    "\n",
    "    trainer_config = {\n",
    "        \"lr\": trial.suggest_loguniform(\"lr\", 1e-5, 1e-3),\n",
    "        \"n_epochs\": 5,  \n",
    "        #\"n_epochs\": trial.suggest_int(\"n_epochs\", 5, 20),\n",
    "        \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 1e-9, 1e-1),\n",
    "        \"batch_size\": 128,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "    \n",
    "    pprint({**config, **trainer_config})\n",
    "\n",
    "    # Create data loaders with current seed\n",
    "    g_train_dl = torch.Generator()\n",
    "    g_train_dl.manual_seed(seed)\n",
    "    train_dataloader = DataLoader(train_dataset, \n",
    "                                  batch_size=trainer_config[\"batch_size\"],\n",
    "                                  shuffle=True,\n",
    "                                  num_workers=NUM_WORKERS,\n",
    "                                  worker_init_fn=seed_worker,  # NEW 2022-12-05\n",
    "                                  generator=g_train_dl,                 # NEW 2022-12-05 \n",
    "                                  collate_fn=train_dataset.collate_fn)\n",
    "    val_dataloader = DataLoader(val_dataset, \n",
    "                                batch_size=trainer_config[\"batch_size\"],\n",
    "                                shuffle=False,\n",
    "                                num_workers=NUM_WORKERS,\n",
    "                                collate_fn=val_dataset.collate_fn)    \n",
    "            \n",
    "    clf_model = RecurrentClassifier(config, vocab, emb_matrix)\n",
    "    t = Trainer(trainer_config)\n",
    "    t.fit(clf_model, train_dataloader, val_dataloader)\n",
    "    val_acc =  t.history[\"val_acc\"][-1]\n",
    "    if val_acc > BEST_ACC:\n",
    "        BEST_ACC = val_acc\n",
    "        #t.save(\"optuna_model.ckpt\")\n",
    "        t.save(f\"{PATH_OUT_DIR}/optuna_model.ckpt\")\n",
    "    \n",
    "    # Clear GPU memory\n",
    "#     del t\n",
    "#     del clf_model\n",
    "#     torch.cuda.empty_cache()  # NEW 2022-12-05\n",
    "\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fcf349",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = create_study(direction=\"maximize\")\n",
    "# you can set more trials\n",
    "study.optimize(objective, n_trials=2)\n",
    "#study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a1b93",
   "metadata": {
    "id": "5b3a1b93"
   },
   "source": [
    "## Launch and save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yewtPFNMSHvb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"freeze\": False,\n",
    "    \"cell_type\": \"LSTM\",\n",
    "    \"cell_dropout\": 4.798608743508714e-08,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 571,\n",
    "    \"out_activation\": \"relu\",\n",
    "    \"bidirectional\": False,\n",
    "    \"out_dropout\": 0.00031547702436796987,\n",
    "    \"out_sizes\": [374, 374, 374],\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"lr\": 0.0002448300553686371,\n",
    "    \"n_epochs\": 5,\n",
    "    \"weight_decay\": 3.333872612242237e-06,\n",
    "    \"batch_size\": 128,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "#clf_model = RecurrentClassifier(config, vocab, emb_matrix)\n",
    "\n",
    "#[0.5016433596611023, 0.4965958297252655, 0.4965958297252655, 0.4965958297252655, 0.5137926936149597]\n",
    "#CLB: [0.4965958297252655, 0.5296396017074585, 0.5178424715995789, 0.5468951463699341, 0.5472473502159119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = {'batch_size': 128,\n",
    "#  'bidirectional': True,\n",
    "#  'cell_dropout': 6.654706392076999e-05,\n",
    "#  'cell_type': 'LSTM',\n",
    "#  'device': 'cuda',\n",
    "#  'freeze': True,\n",
    "#  'hidden_size': 363,\n",
    "#  'lr': 0.00014010022035173308,\n",
    "#  #'n_epochs': 5,\n",
    "#  'n_epochs': 10,\n",
    "#  'num_layers': 3,\n",
    "#  'out_activation': 'tanh',\n",
    "#  'out_dropout': 3.6227682571088135e-09,\n",
    "#  'out_sizes': [],\n",
    "#  'verbose': False,\n",
    "#  'weight_decay': 5.513482572816943e-08}\n",
    "\n",
    "# config = {\n",
    "#     \"freeze\": cfg['freeze'],\n",
    "#     \"cell_type\": cfg['cell_type'],\n",
    "#     \"cell_dropout\": cfg['cell_dropout'],\n",
    "#     \"num_layers\": cfg['num_layers'],\n",
    "#     \"hidden_size\": cfg['hidden_size'],\n",
    "#     \"out_activation\": cfg['out_activation'],\n",
    "#     \"bidirectional\": cfg['bidirectional'],\n",
    "#     \"out_dropout\": cfg['out_dropout'],\n",
    "#     \"out_sizes\": cfg['out_sizes'],\n",
    "# }\n",
    "\n",
    "# trainer_config = {\n",
    "#     \"lr\": cfg['lr'],\n",
    "#     \"n_epochs\": cfg['n_epochs'],\n",
    "#     \"weight_decay\": cfg['weight_decay'],\n",
    "#     \"batch_size\": 128,\n",
    "#     \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# }\n",
    "# clf_model = RecurrentClassifier(config, vocab, emb_matrix)\n",
    "\n",
    "# [0.5000587105751038, 0.49812182784080505, 0.5076887011528015, 0.5145556926727295, 0.5227138996124268]\n",
    "# DP=1: [0.5197793245315552, 0.5039323568344116, 0.5282896757125854, 0.5182533264160156, 0.5300504565238953]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JVeWxOa05MNf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2022-12-05T1346: from Trial 20 (0.508 .. 0.557)\n",
    "cfg = {'batch_size': 128,\n",
    " 'bidirectional': False,\n",
    " 'cell_dropout': 0.00021809889870001576,\n",
    " 'cell_type': 'LSTM',\n",
    " 'device': 'cuda',\n",
    " 'freeze': False,\n",
    " 'hidden_size': 837,\n",
    " 'lr': 0.0005646640795179067,\n",
    " #'n_epochs': 5,\n",
    " 'n_epochs': 10,\n",
    " 'num_layers': 1,\n",
    " 'out_activation': 'relu',\n",
    " 'out_dropout': 3.26822157581284e-05,\n",
    " 'out_sizes': [165],\n",
    " 'verbose': False,\n",
    " 'weight_decay': 1.4724415358265257e-06}\n",
    "\n",
    "config = {\n",
    "    \"freeze\": cfg['freeze'],\n",
    "    \"cell_type\": cfg['cell_type'],\n",
    "    \"cell_dropout\": cfg['cell_dropout'],\n",
    "    \"num_layers\": cfg['num_layers'],\n",
    "    \"hidden_size\": cfg['hidden_size'],\n",
    "    \"out_activation\": cfg['out_activation'],\n",
    "    \"bidirectional\": cfg['bidirectional'],\n",
    "    \"out_dropout\": cfg['out_dropout'],\n",
    "    \"out_sizes\": cfg['out_sizes'],\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"lr\": cfg['lr'],\n",
    "    \"n_epochs\": cfg['n_epochs'],\n",
    "    \"weight_decay\": cfg['weight_decay'],\n",
    "    \"batch_size\": 128,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "# Seed42:\n",
    "# val_loss: ['0.693', >>>'0.688', '0.690', '0.698', '0.715', '0.777', '0.837', '0.878', '1.068', '1.069']\n",
    "# val_acc : ['0.503', '0.540', '0.552', '0.549', '0.552', '0.550', >>>'0.553', '0.552', '0.546', '0.548']\n",
    "\n",
    "# Seed 43:\n",
    "# val_loss: ['0.692', '0.691', >>>'0.689', '0.698', '0.725', '0.750', '0.837', '0.962', '1.035', '1.227']\n",
    "# val_acc : ['0.519', '0.538', '0.541', >>>'0.552', '0.552', '0.551', '0.551', '0.550', '0.548', '0.546']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aN41EDwHWfHv",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_seeds(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35825b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders with current seed\n",
    "g_train_dl = torch.Generator()\n",
    "g_train_dl.manual_seed(seed)\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=trainer_config[\"batch_size\"],\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              worker_init_fn=seed_worker,  # NEW 2022-12-05\n",
    "                              generator=g_train_dl,                 # NEW 2022-12-05 \n",
    "                              collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                            batch_size=trainer_config[\"batch_size\"],\n",
    "                            shuffle=False,\n",
    "                            num_workers=NUM_WORKERS,\n",
    "                            collate_fn=val_dataset.collate_fn)    \n",
    "\n",
    "\n",
    "#init_seeds(44)\n",
    "init_seeds(seed)\n",
    "g_train_dl = torch.Generator()\n",
    "g_train_dl.manual_seed(torch.initial_seed())\n",
    "\n",
    "clf_model = RecurrentClassifier(config, vocab, emb_matrix)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=trainer_config[\"batch_size\"],\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              worker_init_fn=seed_worker,  # NEW 2022-12-05\n",
    "                              generator=g_train_dl,                 # NEW 2022-12-05 \n",
    "                              collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                            batch_size=trainer_config[\"batch_size\"],\n",
    "                            shuffle=False,\n",
    "                            num_workers=NUM_WORKERS,\n",
    "                            collate_fn=val_dataset.collate_fn)\n",
    "t = Trainer(trainer_config)\n",
    "t.fit(clf_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HuE-Ne5yMKaT",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"val_loss:\", [f\"{x:.3f}\" for x in t.history['val_loss']])\n",
    "print(\"val_acc :\", [f\"{x:.3f}\" for x in t.history['val_acc']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rUTmrUqdSvIX",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t.history['train_loss'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D7xoQ0MkTOP1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t.history['val_loss'], \"bo-\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bFJiLTLTRdg",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.history['val_acc'])\n",
    "plt.plot(t.history['val_acc'], \"bo-\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c2a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory\n",
    "del t\n",
    "del clf_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()  # NEW 2022-12-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "O23EEu25K_O5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False  # Below is Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a9095",
   "metadata": {
    "id": "4b8a9095"
   },
   "source": [
    "## TMP: Pre-debug section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_DEBUG_STOP = True\n",
    "\n",
    "# Launch split-train-predict-metrics cycle for several seeds\n",
    "def get_model_score_distribution(model_tag: str, df: pd.DataFrame, launch_cnt: int = 5, verbose=True):\n",
    "\n",
    "    # Global vars, required for DO_DEBUG_STOP case, to continue writing code on the root notebook level\n",
    "    global X_train, y_train, X_test, y_test, seed\n",
    "\n",
    "    result = []\n",
    "    print(\"Legend: seed; X_train shape; X_test_shape; y_train shape,hash,sum; y_test shape,hash,sum\")\n",
    "    for seed in range(42, 42 + launch_cnt):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df[COL_FEATURES + [COL_PCR]], df[COL_LABEL],\n",
    "            # stratify=df[COL_LABEL], # Note: stratification leads to the same test set (though shuffled)\n",
    "            shuffle=True,\n",
    "            random_state = seed, \n",
    "            test_size = TEST_SIZE\n",
    "        )\n",
    "        # Note: equal hash means binary equality, equal sum means the same rows but shuffled\n",
    "        print(f\"After split: {seed}, {X_train.shape}; {X_test.shape}; {y_train.shape},{calc_hash_for_seq(y_train)},{sum(y_train)};\"\n",
    "              + f\" {y_test.shape},{calc_hash_for_seq(y_test)},{sum(y_test)}\")\n",
    "\n",
    "        # Separate price_change_ratio from the data\n",
    "        pcr_train = X_train[COL_PCR]; X_train.drop(COL_PCR, axis=1, inplace=True)\n",
    "        pcr_test = X_test[COL_PCR]; X_test.drop(COL_PCR, axis=1, inplace=True)\n",
    "\n",
    "        if DO_DEBUG_STOP:\n",
    "            assert False, \"Debug-stop fired. Now you could use the above global vars on any notebook cells.\"\n",
    "\n",
    "        # Launch model-specific method\n",
    "        y_pred = None\n",
    "        if model_tag.startswith('dummy_'):\n",
    "            y_pred = train_model_and_get_predictions__sklearn_classifier(model_tag, X_train, y_train, X_test, seed)\n",
    "        elif model_tag == 'ant1':\n",
    "            y_pred = train_model_and_get_predictions__ant1(model_tag, X_train, y_train, X_test, seed)\n",
    "        else:\n",
    "            assert False, f\"Unexpected model tag: {model_tag}\"\n",
    "\n",
    "        # Calc score\n",
    "        score1 = accuracy_score(y_test, y_pred)\n",
    "        #score2 = calc_real_profit_perc(y_pred, pcr_test)\n",
    "        #score3 = calc_real_profit_perc(y_train[:100], pcr_train[:100])\n",
    "        #result.append(f\"{score1:.5f}, {score2:.2f}%, {score3:.2f}%\")\n",
    "        result.append(score1)\n",
    "            \n",
    "        if verbose:\n",
    "            print(confusion_matrix(y_test, y_pred))\n",
    "            print(classification_report(y_test, y_pred, digits=3))\n",
    "                    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c663a",
   "metadata": {
    "id": "801c663a"
   },
   "source": [
    "## Launch the model training/estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6fce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"dummy__most_frequent\"\n",
    "results = get_model_score_distribution(model_tag, df_final, verbose=False)\n",
    "print(\"Sorted results (accuracy):\", sorted(results))\n",
    "print(f\"Mean accuracy: {np.mean(results):.3f} +- {np.std(results):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e48423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"dummy__uniform\"\n",
    "results = get_model_score_distribution(model_tag, df_final, launch_cnt = 5, verbose=False)\n",
    "print(\"Sorted results (accuracy):\", sorted(results))\n",
    "print(f\"Mean accuracy: {np.mean(results):.3f} +- {np.std(results):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"ant1\"\n",
    "results = get_model_score_distribution(model_tag, df_final, launch_cnt = 5, verbose=False)\n",
    "print(\"Sorted results (accuracy):\", sorted(results))\n",
    "print(f\"Mean accuracy: {np.mean(results):.3f} +- {np.std(results):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f_Eg93Ds9ZQG",
   "metadata": {},
   "outputs": [],
   "source": [
    "var2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TK0bsc8Q8LFC",
   "metadata": {},
   "outputs": [],
   "source": [
    "def x():\n",
    "  global var3, var4\n",
    "  var3 = 3\n",
    "  var4 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NWbV-ep79c6R",
   "metadata": {},
   "outputs": [],
   "source": [
    "x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nJdCuL_c9f4s",
   "metadata": {},
   "outputs": [],
   "source": [
    "var4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JwYhylux9gha",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
